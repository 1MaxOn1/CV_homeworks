{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11779879,"sourceType":"datasetVersion","datasetId":7395580},{"sourceId":11780051,"sourceType":"datasetVersion","datasetId":7395710},{"sourceId":12008413,"sourceType":"datasetVersion","datasetId":7554627}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install albumentations","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:19:44.894175Z","iopub.execute_input":"2025-06-03T16:19:44.894733Z","iopub.status.idle":"2025-06-03T16:19:47.877268Z","shell.execute_reply.started":"2025-06-03T16:19:44.894703Z","shell.execute_reply":"2025-06-03T16:19:47.876449Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"%%capture\n!pip install --upgrade -q wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:19:47.878901Z","iopub.execute_input":"2025-06-03T16:19:47.879146Z","iopub.status.idle":"2025-06-03T16:20:03.912859Z","shell.execute_reply.started":"2025-06-03T16:19:47.879123Z","shell.execute_reply":"2025-06-03T16:20:03.912059Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"%%capture\n!pip install lightning","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:20:03.913928Z","iopub.execute_input":"2025-06-03T16:20:03.914219Z","iopub.status.idle":"2025-06-03T16:21:14.134146Z","shell.execute_reply.started":"2025-06-03T16:20:03.914182Z","shell.execute_reply":"2025-06-03T16:21:14.133381Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import torch\nfrom torch import nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn import functional as F\nimport os\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport albumentations as A\nimport lightning as l\nfrom torchmetrics import MetricCollection\nfrom torchmetrics.classification import BinaryPrecision, BinaryRecall\nfrom lightning.pytorch.callbacks import TQDMProgressBar\nfrom torchmetrics.detection import MeanAveragePrecision\nfrom torchvision.ops import box_iou\nimport math","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:21:14.135896Z","iopub.execute_input":"2025-06-03T16:21:14.136133Z","iopub.status.idle":"2025-06-03T16:21:27.496375Z","shell.execute_reply.started":"2025-06-03T16:21:14.136108Z","shell.execute_reply":"2025-06-03T16:21:27.495815Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.8' (you have '2.0.5'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from pytorch_lightning.loggers import WandbLogger\nwandb_logger = WandbLogger()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:21:27.497139Z","iopub.execute_input":"2025-06-03T16:21:27.497498Z","iopub.status.idle":"2025-06-03T16:21:28.014812Z","shell.execute_reply.started":"2025-06-03T16:21:27.497472Z","shell.execute_reply":"2025-06-03T16:21:28.014240Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import wandb\nfrom pytorch_lightning.loggers import WandbLogger\n\nwandb.login(key = '7ade9459940c133dce45cacda59977617e1ae315')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:21:28.015512Z","iopub.execute_input":"2025-06-03T16:21:28.015724Z","iopub.status.idle":"2025-06-03T16:21:35.640444Z","shell.execute_reply.started":"2025-06-03T16:21:28.015707Z","shell.execute_reply":"2025-06-03T16:21:35.639907Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmaximmalahovsky14\u001b[0m (\u001b[33mmaximmalahovsky14-ITMO University\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"class Yolov1Custom(nn.Module):\n    def __init__(self, S, B, C):\n        super().__init__()\n        self.B = B\n        self.C = C\n        self.S = S\n        self.backbone = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3),\n            nn.BatchNorm2d(64),\n            nn.LeakyReLU(0.1),\n            nn.MaxPool2d(kernel_size = 2),\n\n            nn.Conv2d(64, 192, kernel_size = 3, padding = 1),\n            nn.LeakyReLU(0.1),\n            nn.MaxPool2d(kernel_size = 2),\n\n            nn.Conv2d(192, 128, kernel_size = 1),\n            nn.LeakyReLU(0.1),\n            nn.Conv2d(128, 256, kernel_size = 3, padding = 1),\n            nn.LeakyReLU(0.1),\n            nn.Conv2d(256, 256, kernel_size = 1),\n            nn.LeakyReLU(0.1),\n            nn.Conv2d(256, 512, kernel_size = 3, padding = 1),\n            nn.LeakyReLU(0.1),\n            nn.MaxPool2d(kernel_size = 2),\n\n            nn.Conv2d(512, 256, kernel_size = 1),\n            nn.LeakyReLU(0.1),\n            nn.Conv2d(256, 512, kernel_size = 3, padding = 1),\n            nn.LeakyReLU(0.1),\n            \n            nn.Conv2d(512, 256, kernel_size = 1),\n            nn.LeakyReLU(0.1),\n            nn.Conv2d(256, 512, kernel_size = 3, padding = 1),\n            nn.LeakyReLU(0.1),\n\n            nn.Conv2d(512, 256, kernel_size = 1),\n            nn.LeakyReLU(0.1),\n            nn.Conv2d(256, 512, kernel_size = 3, padding = 1),\n            nn.LeakyReLU(0.1),\n\n            nn.Conv2d(512, 256, kernel_size = 1),\n            nn.LeakyReLU(0.1),\n            nn.Conv2d(256, 512, kernel_size = 3, padding = 1),\n            nn.LeakyReLU(0.1),\n\n            nn.Conv2d(512, 512, kernel_size = 1),\n            nn.LeakyReLU(0.1),\n            nn.Conv2d(512, 1024, kernel_size = 3, padding = 1),\n            nn.LeakyReLU(0.1),\n            nn.MaxPool2d(kernel_size = 2),\n\n            nn.Conv2d(1024, 512, kernel_size = 1),\n            nn.LeakyReLU(0.1),\n            nn.Conv2d(512, 1024, kernel_size = 3, padding = 1),\n            nn.LeakyReLU(0.1),\n\n            nn.Conv2d(1024, 512, kernel_size = 1),\n            nn.LeakyReLU(0.1),\n            nn.Conv2d(512, 1024, kernel_size = 3, padding = 1),\n            nn.LeakyReLU(0.1),\n\n            nn.Conv2d(1024, 1024, kernel_size = 3, padding = 1),\n            nn.LeakyReLU(0.1),\n            nn.Conv2d(1024, 1024, kernel_size = 3, stride = 2, padding = 1),\n            nn.LeakyReLU(0.1),\n\n            nn.Conv2d(1024, 1024, kernel_size = 3, padding = 1),\n            nn.LeakyReLU(0.1),\n            nn.Conv2d(1024, 1024, kernel_size = 3, padding = 1),\n            nn.LeakyReLU(0.1),\n            nn.Conv2d(1024, 1024, kernel_size = 4, padding = 1),\n            nn.LeakyReLU(0.1)\n        )\n\n        self.preds = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(self.S * self.S* 1024, 4096),\n            nn.ReLU(),\n            nn.Linear(4096, self.S *self.S * (self.C + self.B * 5 )),\n            nn.ReLU()\n        )\n\n    def forward(self, x):\n        x = self.backbone(x)\n        x = self.preds(x)\n        return x.view(-1, self.S, self.S, 5 * self.B + self.C)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:21:35.641144Z","iopub.execute_input":"2025-06-03T16:21:35.641574Z","iopub.status.idle":"2025-06-03T16:21:35.652186Z","shell.execute_reply.started":"2025-06-03T16:21:35.641555Z","shell.execute_reply":"2025-06-03T16:21:35.651454Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"df = pd.DataFrame(columns = ['image_path', 'label_path'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:21:35.652960Z","iopub.execute_input":"2025-06-03T16:21:35.653198Z","iopub.status.idle":"2025-06-03T16:21:35.669785Z","shell.execute_reply.started":"2025-06-03T16:21:35.653183Z","shell.execute_reply":"2025-06-03T16:21:35.669098Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"images = sorted(os.listdir('/kaggle/input/pigs-data/tmp/frames'))\nlabels = sorted(os.listdir('/kaggle/input/pigs-data/tmp/obj_Train_data'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:21:35.670527Z","iopub.execute_input":"2025-06-03T16:21:35.670898Z","iopub.status.idle":"2025-06-03T16:21:35.725706Z","shell.execute_reply.started":"2025-06-03T16:21:35.670880Z","shell.execute_reply":"2025-06-03T16:21:35.725248Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"for index in range(len(images)):\n    if index >= 520:\n        break\n    elif images[index].split('.')[0] == labels[index].split('.')[0]:\n        df.loc[len(df)] = [images[index], labels[index]]\n    else:\n        print(images[index], labels[index])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:21:35.727605Z","iopub.execute_input":"2025-06-03T16:21:35.728292Z","iopub.status.idle":"2025-06-03T16:21:36.103028Z","shell.execute_reply.started":"2025-06-03T16:21:35.728269Z","shell.execute_reply":"2025-06-03T16:21:36.102221Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class PigsDataset(Dataset):\n    def __init__(self, df, S, B, C, transform = None):\n        self.df = df\n        self.S = S\n        self.C = C\n        self.B = B\n        self.path_im = Path('/kaggle/input/pigs-data/tmp/frames')\n        self.path_lab = Path('/kaggle/input/pigs-data/tmp/obj_Train_data')\n        if transform is None:\n            self.trasnform = A.Compose([\n                A.Resize(480, 480),\n                A.Normalize(),\n                A.ToTensorV2()\n            ])\n    \n    def __len__(self):\n        return self.df.shape[0]\n\n    def __getitem__(self, idx):\n        image_path = self.df['image_path'][idx]\n        image = Image.open(self.path_im / Path(image_path)).convert('RGB')\n        im_arr = np.asarray(image)\n\n        im_arr = self.trasnform(image = im_arr)['image']\n        \n        labels_path = self.df['label_path'][idx]\n        labels_tensor = torch.zeros(self.S, self.S, (self.B * 5 + self.C))\n        \n        with open(self.path_lab / Path(labels_path), 'r') as file:\n            for line in file.readlines():\n                parts = [float(l) for l in line.split()]\n                \n                class_id = int(parts[0])\n                x_center_norm = parts[1]\n                y_center_norm = parts[2]\n                width_norm = parts[3]\n                height_norm = parts[4]\n\n                x_grid = min(int(x_center_norm * self.S), self.S - 1)\n                y_grid = min(int(y_center_norm * self.S), self.S - 1)\n\n                x_cell = (x_center_norm * self.S) - x_grid\n                y_cell = (y_center_norm * self.S) - y_grid\n                \n                w_sqrt = math.sqrt(width_norm)\n                h_sqrt = math.sqrt(height_norm)\n\n                class_one_hot = torch.zeros(self.C)\n                class_one_hot[class_id] = 1.0\n                \n                box_info = torch.tensor([1.0, x_cell, y_cell, w_sqrt, h_sqrt], dtype=torch.float32)\n                \n                labels_tensor[y_grid, x_grid, :5] = box_info \n                labels_tensor[y_grid, x_grid, 5 : 5 + self.C] = class_one_hot\n        \n        return im_arr, labels_tensor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:21:36.103886Z","iopub.execute_input":"2025-06-03T16:21:36.104103Z","iopub.status.idle":"2025-06-03T16:21:36.113416Z","shell.execute_reply.started":"2025-06-03T16:21:36.104086Z","shell.execute_reply":"2025-06-03T16:21:36.112627Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def calc_coords(inp):\n    x_c = inp[:, 0]\n    y_c = inp[:, 1]\n    w = inp[:, 2]\n    h = inp[:, 3]\n\n    w = torch.clamp(w, min=0.0)\n    h = torch.clamp(h, min=0.0)\n\n    x_min = x_c - w / 2\n    y_min = y_c - h / 2\n    x_max = x_c + w / 2\n    y_max = y_c + h / 2\n    \n    x_min = torch.clamp(x_min, 0.0, 1.0)\n    y_min = torch.clamp(y_min, 0.0, 1.0)\n    x_max = torch.clamp(x_max, 0.0, 1.0)\n    y_max = torch.clamp(y_max, 0.0, 1.0)\n\n    return torch.stack([x_min, y_min, x_max, y_max], dim=-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:21:36.114275Z","iopub.execute_input":"2025-06-03T16:21:36.114517Z","iopub.status.idle":"2025-06-03T16:21:36.127221Z","shell.execute_reply.started":"2025-06-03T16:21:36.114498Z","shell.execute_reply":"2025-06-03T16:21:36.126604Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def yolo_loss(pred, label, alpha_coord, alpha_noo, B = 2):\n    mask = label[:, :, :, 0] > 0\n    mask_no = label[:, :, :, 0] == 0\n    start_bbox = 1\n    fin_bbox = 5\n    \n    # получение элементов, которые внутри себя содержат объекты\n    obj_p = pred[mask]\n    obj_l = label[mask]\n    iou_res = torch.zeros((obj_l.shape[0], B))\n\n    for index in range(B):\n        val = obj_p[:, start_bbox:fin_bbox]\n        start_bbox += 5\n        fin_bbox += 5\n        real_coords_p = calc_coords(val) \n        real_coords_l = calc_coords(obj_l[:, 1:5])\n        iou_matrix = box_iou(real_coords_p, real_coords_l)\n        iou_values = torch.diag(iou_matrix)\n        iou_res[:, index] = iou_values \n\n    coord_b = iou_res.argmax(dim=1)\n    most_sim_start = (coord_b * 5 + 1).to(obj_p.device)\n    conf_ind = (coord_b * 5).to(obj_p.device)\n    bbox_ind = most_sim_start.unsqueeze(1) + torch.arange(4, device = obj_p.device).unsqueeze(0) \n    bbox_pred = torch.gather(input = obj_p, index = bbox_ind, dim = 1)\n    conf_pred = torch.gather(input = obj_p, index = conf_ind.unsqueeze(1), dim = 1).squeeze(1)\n\n    # расчет лоссов\n    x_loss = F.mse_loss(input = bbox_pred[:, 0], \n                        target = obj_l[:, 1])\n    y_loss = F.mse_loss(input = bbox_pred[:, 1], \n                        target = obj_l[:, 2])\n\n    center_loss = alpha_coord * (x_loss + y_loss)\n\n    w_loss = F.mse_loss(input = torch.sqrt(bbox_pred[:, 2]), \n                        target = torch.sqrt(obj_l[:, 3]))\n    h_loss = F.mse_loss(input = torch.sqrt(bbox_pred[:, 3]), \n                        target = torch.sqrt(obj_l[:, 4]))\n\n    size_loss = alpha_coord * (w_loss + h_loss)\n\n    conf_loss = F.binary_cross_entropy_with_logits(input = conf_pred, \n                                                   target = iou_res.max(dim=1)[0].to(conf_pred.device))\n\n    class_loss = F.binary_cross_entropy_with_logits(input = obj_p[:, -1],\n                                                   target = obj_l[:, -1])\n    \n    no_obj_p = pred[mask_no]\n    no_obj_l = label[mask_no]\n    all_conf_indices_no_obj = torch.arange(B, device=no_obj_p.device) * 5\n    all_conf_preds_no_obj = torch.gather(no_obj_p, 1, all_conf_indices_no_obj.unsqueeze(0).expand(no_obj_p.shape[0], -1))\n    target_no_obj_conf = torch.zeros_like(all_conf_preds_no_obj)\n    \n    conf_no = F.binary_cross_entropy_with_logits(input = all_conf_preds_no_obj,\n                                                 target = target_no_obj_conf)\n    \n    return center_loss + size_loss + conf_loss + class_loss + alpha_noo * conf_no ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:21:36.127953Z","iopub.execute_input":"2025-06-03T16:21:36.128397Z","iopub.status.idle":"2025-06-03T16:21:36.142458Z","shell.execute_reply.started":"2025-06-03T16:21:36.128372Z","shell.execute_reply":"2025-06-03T16:21:36.141812Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"class LightningYolov1(l.LightningModule):\n    def __init__(self, base_model, loss, alpha_coord, alpha_noo):\n        super().__init__()\n        self.base_model = base_model\n        self.loss = loss\n        self.alpha_coord = alpha_coord\n        self.alpha_noo = alpha_noo\n        self.metrics = MetricCollection({\n            \"obj_prec\": BinaryPrecision(threshold=0.5), \n            \"obj_rec\": BinaryRecall(threshold=0.5),    \n            \"class_prec\": BinaryPrecision(threshold=0.5), \n            \"class_rec\": BinaryRecall(threshold=0.5),    \n            # \"map\": MeanAveragePrecision(iou_type=\"bbox\")\n        })\n        self.val_metrics = self.metrics.clone(prefix = 'val_')\n        self.test_metrics = self.metrics.clone(prefix = 'test_')\n    \n    def forward(self, x):\n        return self.base_model(x)\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        preds = self.forward(x)\n        loss = self.loss(preds, y, self.alpha_coord, self.alpha_noo)\n        self.log('train_loss', loss, on_step = True, on_epoch = True, prog_bar = True, logger = True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        preds = self.forward(x)\n        loss = self.loss(preds, y, self.alpha_coord, self.alpha_noo)\n        \n        pred_class_logits = preds[:, :, :, self.base_model.B * 5 : ].contiguous()\n        true_class_labels = y[:, :, :, 5 ].contiguous()\n\n        pred_class_sigmoid_flat = F.sigmoid(pred_class_logits).flatten()\n        true_class_labels_flat = true_class_labels.flatten()\n        \n        pred_conf_logits = preds[:, :, :, torch.arange(self.base_model.B ) * 5].flatten().contiguous()\n        \n        true_obj_labels = y[:, :, :, 0].contiguous() \n        true_obj_labels_expanded = torch.cat([true_obj_labels,true_obj_labels]).flatten()\n\n        pred_conf_sigmoid_flat = F.sigmoid(pred_conf_logits).flatten()\n        true_obj_labels_flat = true_obj_labels_expanded.flatten()\n                \n        self.val_metrics[\"obj_prec\"].update(pred_conf_sigmoid_flat, true_obj_labels_flat)\n        self.val_metrics[\"obj_rec\"].update(pred_conf_sigmoid_flat, true_obj_labels_flat)\n        self.val_metrics[\"class_prec\"].update(pred_class_sigmoid_flat, true_class_labels_flat) # error\n        self.val_metrics[\"class_rec\"].update(pred_class_sigmoid_flat, true_class_labels_flat)\n        \n        return loss\n\n    def test_step(self, batch, batch_idx):\n        x, y = batch\n        preds = self.forward(x)\n        preds = F.sigmoid(preds[:, : , :, 4:])\n        self.test_metrics.update(preds, y)\n\n    def on_test_epoch_end(self):\n        self.log_dict(self.test_metrics.compute(), prog_bar = True, on_epoch = True)\n        self.test_metrics.reset()\n\n    def on_validation_epoch_end(self):\n        self.log_dict(self.val_metrics.compute(), prog_bar = True, on_epoch = True)\n        self.val_metrics.reset()\n\n    def configure_optimizers(self):\n        return torch.optim.AdamW(self.base_model.parameters(), lr = 1e-4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:21:36.143196Z","iopub.execute_input":"2025-06-03T16:21:36.143389Z","iopub.status.idle":"2025-06-03T16:21:36.158230Z","shell.execute_reply.started":"2025-06-03T16:21:36.143375Z","shell.execute_reply":"2025-06-03T16:21:36.157623Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def nms(preds, conf_thresh = 0.2, iou_thresh = 0.5, B = 2):\n    if preds.dim() == 3:\n        preds = preds.unsqueeze(0)\n\n    batch_nms_results = []\n\n    for i_batch in range(preds.shape[0]):\n        image_preds = preds[i_batch]\n        \n        val_bboxes_only = image_preds[..., :B*5]\n\n        val_reshaped_per_bbox = val_bboxes_only.reshape(*val_bboxes_only.shape[:-1], B, 5)\n        tensor_single_bbox = val_reshaped_per_bbox.reshape(-1, 5)\n\n        tensor_single_bbox[:, 0] = F.sigmoid(tensor_single_bbox[:, 0])\n\n        _, sort_indices = torch.sort(tensor_single_bbox[:, 0], descending=True)\n        \n        sorted_tensor = tensor_single_bbox[sort_indices]\n\n        mask_conf = sorted_tensor[:, 0] > conf_thresh\n        sorted_tensor = sorted_tensor[mask_conf]\n\n        final_boxes_for_image = []\n\n        while sorted_tensor.shape[0] > 0:\n            current_bbox = sorted_tensor[0]\n            final_boxes_for_image.append(current_bbox)\n\n            if sorted_tensor.shape[0] == 1:\n                break\n\n            current_min_max = calc_coords(current_bbox[1:]) \n\n            remaining_bboxes = sorted_tensor[1:]\n            remaining_min_max = calc_coords(remaining_bboxes[:, 1:])\n\n            iou_res = box_iou(current_min_max, remaining_min_max).squeeze(0)\n\n            mask_to_keep = iou_res <= iou_thresh\n\n            sorted_tensor = remaining_bboxes[mask_to_keep]\n        \n        batch_nms_results.append(torch.stack(final_boxes_for_image) if final_boxes_for_image else torch.empty(0, 5, device=preds.device))\n\n    if preds.shape[0] == 1:\n        return batch_nms_results[0]\n    else:\n        return batch_nms_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:21:36.159020Z","iopub.execute_input":"2025-06-03T16:21:36.159286Z","iopub.status.idle":"2025-06-03T16:21:36.173262Z","shell.execute_reply.started":"2025-06-03T16:21:36.159264Z","shell.execute_reply":"2025-06-03T16:21:36.172516Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"class PigsDataModule(l.LightningDataModule):\n    def __init__(self, df, S=7, B=2, C=1, batch_size = 64):\n        self.S = S\n        self.C = C\n        self.B = B\n        self.df = df\n        self.batch_size = batch_size\n        self._log_hyperparams = False \n\n    def setup(self, stage:str):\n        self.data = PigsDataset(df = self.df, S = self.S, B = self.B, C = self.C)\n        self.ind = torch.randperm(len(self.data))\n        self.train_ind = self.ind[:int(0.7*len(self.data))]\n        self.val_ind = self.ind[int(0.7*len(self.data)) : int(0.9*len(self.data))]\n        self.test_ind = self.ind[int(0.9 * len(self.data)) : len(self.data)]\n        self.train = torch.utils.data.Subset(self.data, self.train_ind.tolist())\n        self.val = torch.utils.data.Subset(self.data, self.val_ind.tolist())\n        self.test = torch.utils.data.Subset(self.data, self.test_ind.tolist())\n\n    @property\n    def allow_zero_length_dataloader_with_multiple_devices(self):\n        return False\n\n    def train_dataloader(self):\n        return DataLoader(self.train, batch_size = self.batch_size, num_workers = 4)\n\n    def val_dataloader(self):\n        return DataLoader(self.val, batch_size = self.batch_size, num_workers = 4)\n\n    def test_dataloader(self):\n        return DataLoader(self.test, batch_size = self.batch_size, num_workers = 4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:21:36.174088Z","iopub.execute_input":"2025-06-03T16:21:36.174314Z","iopub.status.idle":"2025-06-03T16:21:36.184487Z","shell.execute_reply.started":"2025-06-03T16:21:36.174292Z","shell.execute_reply":"2025-06-03T16:21:36.183813Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def calculate_map50(preds_batch, targets_batch, B, num_classes, conf_thresh_nms=0.05, iou_thresh_nms=0.5, iou_ap_threshold=0.5):\n    all_detections_flat = [] \n    all_ground_truths_flat = []\n\n    for img_idx in range(targets_batch.shape[0]):\n        gt_image = targets_batch[img_idx]\n        \n        gt_object_mask = gt_image[:, :, 0] > 0.0 \n        gt_object_cells = gt_image[gt_object_mask]\n        \n        if gt_object_cells.shape[0] == 0:\n            continue\n\n        gt_bbox_xywh = gt_object_cells[:, 1:5]\n        gt_class_idx = torch.argmax(gt_object_cells[:, 5:], dim=-1)\n        \n        gt_bbox_xyxy = calc_coords(gt_bbox_xywh)\n\n        for i in range(gt_bbox_xyxy.shape[0]):\n            all_ground_truths_flat.append({\n                'image_idx': img_idx,\n                'bbox': gt_bbox_xyxy[i],\n                'class_id': gt_class_idx[i].item(),\n                'matched': False\n            })\n\n    for img_idx in range(preds_batch.shape[0]):\n        detections_for_image = nms_for_map(preds_batch[img_idx], conf_thresh_nms, iou_thresh_nms, B, num_classes)\n        \n        if detections_for_image.shape[0] == 0:\n            continue\n\n        det_bbox_xywh = detections_for_image[:, 1:5]\n        det_bbox_xyxy = calc_coords(det_bbox_xywh)\n        \n        det_conf = detections_for_image[:, 0]\n        det_class_idx = detections_for_image[:, 5].long()\n\n        for i in range(det_bbox_xyxy.shape[0]):\n            all_detections_flat.append({\n                'image_idx': img_idx,\n                'confidence': det_conf[i].item(),\n                'bbox': det_bbox_xyxy[i],\n                'class_id': det_class_idx[i].item()\n            })\n    \n    all_detections_flat.sort(key=lambda x: x['confidence'], reverse=True)\n\n    aps = []\n\n    for class_id in range(num_classes):\n        class_detections = [d for d in all_detections_flat if d['class_id'] == class_id]\n        class_ground_truths = [gt for gt in all_ground_truths_flat if gt['class_id'] == class_id]\n\n        num_gt_for_class = len(class_ground_truths)\n        num_det_for_class = len(class_detections)\n\n        if num_gt_for_class == 0 and num_det_for_class == 0:\n            continue\n        if num_det_for_class == 0:\n            aps.append(0.0)\n            continue\n        if num_gt_for_class == 0:\n            aps.append(0.0)\n            continue\n\n        TP = torch.zeros(num_det_for_class, device=preds_batch.device)\n        FP = torch.zeros(num_det_for_class, device=preds_batch.device)\n        \n        for gt in class_ground_truths:\n            gt['matched'] = False \n\n        for det_idx, detection in enumerate(class_detections):\n            best_iou = 0.0\n            best_gt_index_in_list = -1\n\n            for gt_list_idx, gt in enumerate(class_ground_truths):\n                if gt['matched']: \n                    continue\n                \n                if detection['image_idx'] != gt['image_idx']:\n                    continue\n\n                iou = box_iou(detection['bbox'].unsqueeze(0), gt['bbox'].unsqueeze(0)).item()\n                if iou > best_iou:\n                    best_iou = iou\n                    best_gt_index_in_list = gt_list_idx\n            \n            if best_iou >= iou_ap_threshold and best_gt_index_in_list != -1:\n                TP[det_idx] = 1\n                class_ground_truths[best_gt_index_in_list]['matched'] = True \n            else:\n                FP[det_idx] = 1\n\n        cum_TP = torch.cumsum(TP, dim=0)\n        cum_FP = torch.cumsum(FP, dim=0)\n\n        precision = cum_TP / (cum_TP + cum_FP)\n        recall = cum_TP / num_gt_for_class\n\n        precision = torch.cat((torch.tensor([1.0], device=precision.device), precision))\n        recall = torch.cat((torch.tensor([0.0], device=recall.device), recall))\n        \n        for i in range(recall.shape[0] - 1, 0, -1):\n            precision[i-1] = torch.max(precision[i-1], precision[i])\n\n        ap = torch.sum((recall[1:] - recall[:-1]) * precision[1:])\n        \n        aps.append(ap.item())\n\n    if len(aps) == 0:\n        return 0.0\n        \n    return sum(aps) / len(aps)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:21:36.185214Z","iopub.execute_input":"2025-06-03T16:21:36.185376Z","iopub.status.idle":"2025-06-03T16:21:36.202488Z","shell.execute_reply.started":"2025-06-03T16:21:36.185364Z","shell.execute_reply":"2025-06-03T16:21:36.201880Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"base_model = Yolov1Custom(S = 7, B = 2, C = 1)\nmodel = LightningYolov1(base_model, yolo_loss, 5, 0.005)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:21:36.203089Z","iopub.execute_input":"2025-06-03T16:21:36.203267Z","iopub.status.idle":"2025-06-03T16:21:38.663179Z","shell.execute_reply.started":"2025-06-03T16:21:36.203254Z","shell.execute_reply":"2025-06-03T16:21:38.662597Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"wandb_logger = WandbLogger(project = 'yolov1-pigs-dataset',\n                          save_dir = 'yolov1_training',\n                          name = 'yolov1_train_pigs') ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:22:33.603254Z","iopub.execute_input":"2025-06-03T16:22:33.603525Z","iopub.status.idle":"2025-06-03T16:22:33.607150Z","shell.execute_reply.started":"2025-06-03T16:22:33.603508Z","shell.execute_reply":"2025-06-03T16:22:33.606446Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"device = torch.device('cuda:1' if torch.cuda.is_available else 'cpu')\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:22:34.968305Z","iopub.execute_input":"2025-06-03T16:22:34.968748Z","iopub.status.idle":"2025-06-03T16:22:34.973366Z","shell.execute_reply.started":"2025-06-03T16:22:34.968726Z","shell.execute_reply":"2025-06-03T16:22:34.972810Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=1)"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"datamodule = PigsDataModule(df, batch_size = 32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:22:35.108898Z","iopub.execute_input":"2025-06-03T16:22:35.109074Z","iopub.status.idle":"2025-06-03T16:22:35.112704Z","shell.execute_reply.started":"2025-06-03T16:22:35.109060Z","shell.execute_reply":"2025-06-03T16:22:35.111872Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"trainer = l.Trainer(\n    max_epochs = 30,\n    log_every_n_steps = 10,\n    callbacks = [TQDMProgressBar()],\n    logger = wandb_logger,\n    devices = [1]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:22:35.230447Z","iopub.execute_input":"2025-06-03T16:22:35.230885Z","iopub.status.idle":"2025-06-03T16:22:35.270664Z","shell.execute_reply.started":"2025-06-03T16:22:35.230869Z","shell.execute_reply":"2025-06-03T16:22:35.270213Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"trainer.fit(model = model, datamodule = datamodule)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:22:35.351754Z","iopub.execute_input":"2025-06-03T16:22:35.351975Z","iopub.status.idle":"2025-06-03T16:43:55.059080Z","shell.execute_reply.started":"2025-06-03T16:22:35.351962Z","shell.execute_reply":"2025-06-03T16:43:55.058392Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.11"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>yolov1_training/wandb/run-20250603_162235-9zewlnis</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/maximmalahovsky14-ITMO%20University/yolov1-pigs-dataset/runs/9zewlnis' target=\"_blank\">yolov1_train_pigs</a></strong> to <a href='https://wandb.ai/maximmalahovsky14-ITMO%20University/yolov1-pigs-dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/maximmalahovsky14-ITMO%20University/yolov1-pigs-dataset' target=\"_blank\">https://wandb.ai/maximmalahovsky14-ITMO%20University/yolov1-pigs-dataset</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/maximmalahovsky14-ITMO%20University/yolov1-pigs-dataset/runs/9zewlnis' target=\"_blank\">https://wandb.ai/maximmalahovsky14-ITMO%20University/yolov1-pigs-dataset/runs/9zewlnis</a>"},"metadata":{}},{"name":"stderr","text":"INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\nINFO: \n  | Name         | Type             | Params | Mode \n----------------------------------------------------------\n0 | base_model   | Yolov1Custom     | 284 M  | train\n1 | metrics      | MetricCollection | 0      | train\n2 | val_metrics  | MetricCollection | 0      | train\n3 | test_metrics | MetricCollection | 0      | train\n----------------------------------------------------------\n284 M     Trainable params\n0         Non-trainable params\n284 M     Total params\n1,138.670 Total estimated model params size (MB)\n78        Modules in train mode\n0         Modules in eval mode\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d758a63fc03b4b2f8dcf8dddc7ba3501"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ","metadata":{}}]}